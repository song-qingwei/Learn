[TOC]

#### 一、集群搭建

虽然 Redis 有持久化功能能够保障 Redis 服务器宕机也能恢复并且只有少量的数据损失，但是由于所有数据在一台服务器上，如果这台服务器出现硬盘故障，那就算是有备份也仍然不可避免数据丢失的问题。

在实际生产环境中，我们不可能只使用一台 Redis 服务器作为我们的缓存服务器，必须要多台实现集群，避免出现单点故障；

Redis 集群没有使用一致性hash, 而是引入了 **哈希槽** 的概念。

Redis 集群有16384个哈希槽，每个key通过`CRC16`校验后对16384取模来决定放置哪个槽。集群的每个节点负责一部分hash槽，举个例子，比如当前集群有3个节点,那么：

- 节点 A 包含 0 到 5500号哈希槽
- 节点 B 包含5501 到 11000 号哈希槽
- 节点 C 包含11001 到 16384号哈希槽

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有N~1个复制品。

要让集群正常工作至少需要3个主节点，这里创建6个 Redis 节点，其中三个为主节点，三个为从节点，对应的 Redis 节点的 ip 和端口对应关系如下（为了简单演示都在同一台机器上面）

```shell
127.0.0.1:7001
127.0.0.1:7002
127.0.0.1:7003
127.0.0.1:7004
127.0.0.1:7005
127.0.0.1:7006
```

##### 1. 安装redis

参考 单节点 Redis 单节点安装；会安装到`/usr/local/redis`目录下

##### 2. 修改配置文件

```shell
# 将安装好的redis拷贝一份到7001目录下
cp -r /usr/local/redis/* /usr/local/cluster/7001/
# 修改配置文件
vim /usr/local/cluster/7001/redis.conf
```

```shell
bind 192.168.225.133
port 7001
daemonize yes
# 开启集群
cluster-enabled yes
# 集群节点配置文件
cluster-config-file /usr/local/cluster/7001/nodes.conf
# 集群连接超时时间
cluster-node-timeout 15000
# 进程pid的文件位置
pidfile /usr/local/cluster/7001/redis_7001.pid
dir /usr/local/cluster/7001/
# 开启AOF
appendonly yes
cluster-migration-barrier 1
cluster-require-full-coverage yes
```

##### 3. 编写启动脚本

```shell
vim /usr/local/cluster/start.sh
```

```shell
#!/bin/bash
./usr/local/redis/bin/redis-server ./usr/local/redis/redis.conf
./usr/local/cluster/7001/bin/redis-server ./usr/local/cluster/7001/redis.conf
./usr/local/cluster/7002/bin/redis-server ./usr/local/cluster/7002/redis.conf
./usr/local/cluster/7003/bin/redis-server ./usr/local/cluster/7003/redis.conf
./usr/local/cluster/7004/bin/redis-server ./usr/local/cluster/7004/redis.conf
./usr/local/cluster/7005/bin/redis-server ./usr/local/cluster/7005/redis.conf
./usr/local/cluster/7006/bin/redis-server ./usr/local/cluster/7006/redis.conf
```

```shell
chmod +x /usr/local/cluster/start
```



##### 4. 开机启动

```shell
sh /usr/local/cluster/start.sh
```

##### 5. 开启集群

这里我们只是开启了6个 Redis 进程而已，它们都还只是独立的状态，还么有组成集群这里我们使用官方提供的工具`redis-trib`，不过这个工具是用`ruby`写的，要先安装`ruby`的环境：

CentOS 7以下环境安装：

```shell
yum -y install ruby rubygems
```

CentOS 7以上环境安装：

```shell
# 安装curl
yum -y install curl
# 配置rvm的key
gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3 7D2BAF1CF37B13E2069D6956105BD0E739499BDB
# 安装rvm
curl -sSL https://get.rvm.io | bash -s stable
# 查找安装后的rvm地址
find / -name rvm -print
source /usr/local/rvm/scripts/rvm
# 查看rvm中已知的ruby版本
rvm list known
# 安装一个ruby版本
rvm install 2.6.0
# 使用一个ruby版本
rvm use 2.6.0
# 卸载一个ruby已知版本
rvm remove 2.0.0
```

![CentOS7以上集群安装rvm](F:\总结\截图\技术篇\Redis\CentOS7以上集群安装rvm.png)

检测是否安装成功：

```shell
ruby -v
```

安装`ruby`和`redis`的连接

```shell
gem install redis
```

```shell
cp /root/tools/redis-3.2.9/src/redis-trib.rb /usr/local/cluster/redis-trib
```

##### 6. 创建集群

```shell
redis-trib create --replicas 1 192.168.225.133:7001 192.168.225.133:7002 192.168.225.133:7003 192.168.225.133:7004 192.168.225.133:7005 192.168.225.133:7006
# 命令的意义
# 给定 redis-trib.rb 程序的命令是 create ， 这表示我们希望创建一个新的集群；
# 选项 --replicas 1 表示我们希望为集群中的每个主节点创建一个从节点；
# 之后跟着的其他参数则是实例的地址列表， 我们希望程序使用这些地址所指示的实例来创建新集群
```

##### 7. 测试集群

```shell
# -c:启动集群模式
./7001/bin/redis-cli -h 192.168.225.133 -p 7001 -c
# 进入redis客户端控制台后查看信息
info replication
# 查看集群信息
cluster slots
```

查看集群状态

```shell
cd /usr/local/cluster
./redis-trib check 192.168.225.133:7001
```

##### 8. 向集群中添加主节点

```shell
# 前面的节点表示要加入的节点,第二个节点表示要加入的集群中的任意一个节点，用来标识这个集群
./redis-trib add-node 192.168.225.133:7007 192.168.225.133:7001
./redis-trib check 192.168.225.133:7007
# 里面0 slots,也就是说节点7没有分配哈希槽,需要我们手动对集群进行重新分片迁移
# 这个命令是用来迁移slot节点的,后面的192.168.225.133:7001是表示哪个集群的，7001-7007都是可以的
./redis-trib reshard 192.168.225.133:7001
```

它提示我们需要迁移多少slot到7007上，我们可以算一下：16384/4 = 4096，也就是说，为了平衡分配起见，我们需要移动4096个槽点到7007上。

它又提示我们，接受的node ID是多少，7007的id 我们通过上面就可以看到；

接着， `redis-trib`会向你询问重新分片的源节点（source node）， 也即是， 要从哪个节点中取出 4096 个哈希槽， 并将这些槽移动到7007节点上面。

如果我们不打算从特定的节点上取出指定数量的哈希槽， 那么可以向`redis-trib`输入 all ， 这样的话， 集群中的所有主节点都会成为源节点，`redis-trib`将从各个源节点中各取出一部分哈希槽， 凑够 4096 个， 然后移动到7007节点上；

接下来就开始迁移了，并且会询问你是否确认；

输入yes并回车后，`redis-trib`就会正式执行重新分片操作，将制定的哈希槽从源节点一个个移动到7007节点。

##### 9. 向集群中添加从节点

新建一个 7008从节点，作为7007的从节点；

```shell
# --slave:表示是加入到从节点中
# --master-id:表示指定的主节点node id
./redis-trib add-node --slave --master-id efc3131fbdc6cf929720e0e0f7136cae85657481 192.168.225.133:7008 192.168.225.133:7001
```

##### 10. 移除一个主节点

```shell
# ip:port表示要移除的节点所在的集群
# <node-id>表示待移除的节点ID
./redis-trib del-node 192.168.225.133:7007 `<node-id>`
```

这里报错了，提示我们7007节点里面有数据，让我们把7007节点里的数据移除出去，也就是说需要重新分片，这个和上面增加节点的方式一样：

```shell
./redis-trib reshard 192.168.225.133:7001
```

提示输入#1（待移除节点ID）:`<node-id>`

提示输入#2:`done`

输入yes并回车后，`redis-trib`就会正式执行重新分片操作，然后再次执行移除操作

##### 11. 移除一个从节点

```shell
./redis-trib del-node 192.168.225.133:7008 44321e7d619410dc4e0a8745366610a0d06d2395
```

##### 12. Redis 性能测试

Redis 自带了性能测试工具`redis-benchmark`

#### 二、主从复制

复制的作用是把 Redis 的数据库复制多个副本部署在不同的服务器上，如果其中一台服务器出现故障，也能快速迁移到其他服务器上提供服务。 复制功能可以实现当一台 Redis 服务器的数据更新后，自动将新的数据同步到其他服务器上。

主从复制就是我们常见的`master/slave`模式， 主数据库可以进行读写操作，当写操作导致数据发生变化时会自动将数据同步给从数据库。而一般情况下，从数据库是只读的，并接收主数据库同步过来的数据。 一个主数据库可以有多个从数据库。

```shell
准备两台服务器，分别安装redis ， server1 server2
在server2的redis.conf文件中增加 slaveof server1-ip 6379 、 同时将bind ip注释掉，允许所有ip访问
启动server2
访问server2的redis客户端，输入 INFO replication
通过在master机器上输入命令，比如set foo bar 、 在slave服务器就能看到该值已经同步过来了
```

##### 1. 全量复制

Redis 全量复制一般发生在 Slave 初始化阶段，这时 Slave 需要将 Master 上的所有数据都复制一份。具体步骤：

![全量复制](F:\总结\截图\技术篇\Redis\全量复制.png)

完成上面几个步骤后就完成了 Slave 服务器数据初始化的所有操作，Savle 服务器此时可以接收来自用户的读请求。

`master/slave`复制策略是采用乐观复制，也就是说可以容忍在一定时间内`master/slave`数据的内容是不同的，但是两者的数据会最终同步。具体来说，Redis 的主从同步过程本身是异步的，意味着 Master 执行完客户端请求的命令后会立即返回结果给客户端，然后异步的方式把命令同步给 Slave。

这一特征保证启用`master/slave`后 Master 的性能不会受到影响。

但是另一方面，如果在这个数据不一致的窗口期间，`master/slave`因为网络问题断开连接，而这个时候，Master 是无法得知某个命令最终同步给了多少个 Slave 数据库。不过 Redis 提供了一个配置项来限制只有数据至少同步给多少个 Slave 的时候，Master 才是可写的：

```shell
# 表示只有当3个或以上的slave连接到master，master才是可写的
min-slaves-to-write 3
# 表示允许slave最长失去连接的时间，如果10秒还没收到slave的响应，则master认为该slave以断开
min-slaves-max-lag 10
```

通过在从节点上进行端口监听：

```shell
./7001/bin/redis-cli -h 192.168.225.133 -p 7004 -c
REPLCONF listening-port 7004
sync
```

然后在主节点进行数据操作：此时会在7004从节点上显示操作的命令并将数据同步

##### 2. 增量复制

从`redis 2.8`开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。

Master node 会在内存中创建一个`backlog`，Master 和 Slave 都会保存一个`replica offset`还有一个`master id`，`offset`就是保存在`backlog`中的。如果 Master 和 Slave 网络连接恢复了，Slave 会让 Master 从上次的`replica offset`开始继续复制。但是如果没有找到对应的`offset`，那么就会执行一次全量同步。

##### 3. 无硬盘复制

Redis 复制的工作原理基于 RDB 方式的持久化实现的，也就是 Master 在后台保存 RDB 快照，Slave 接收到 RDB 文件并载入，但是这种方式会存在一些问题：

1.  当 Master 禁用 RDB 时，如果执行了复制初始化操作，Redis 依然会生成 RDB 快照，当 Master 下次启动时执行该 RDB 文件的恢复，但是因为复制发生的时间点不确定，所以恢复的数据可能是任何时间点的。就会造成数据出现问题；
2. 当硬盘性能比较慢的情况下（网络硬盘），那初始化复制过程会对性能产生影响；

因此 2.8.18 以后的版本，Redis 引入了无硬盘复制选项，可以不需要通过 RDB 文件去同步，直接发送数据，通过以下配置来开启该功能：

```shell
repl-diskless-sync yes
```

master** 在内存中直接创建 RDB，然后发送给 Slave，不会在自己本地落地磁盘了。

#### 三、哨兵机制

在前面讲的`master/slave`模式，在一个典型的一主多从的系统中，slave在整个体系中起到了数据冗余备份和读写分离的作用。当master遇到异常终端后，需要从slave中选举一个新的master继续对外提供服务，比如在zk中通过leader选举、kafka中可以基于zk的节点实现master选举。所以在redis中也需要一种机制去实现master的决策，redis并没有提供自动master选举功能，而是需要借助一个哨兵来进行监控。

##### 什么是哨兵

顾名思义，哨兵的作用就是监控Redis系统的运行状况，它的功能包括：

1. 监控master和slave是否正常运行
2.  master出现故障时自动将slave数据库升级为master

哨兵是一个独立的进程，使用哨兵后的架构图：

![单哨兵架构图](F:\总结\截图\技术篇\Redis\单哨兵架构图.png)

为了解决master选举问题，又引出了一个单点问题，也就是哨兵的可用性如何解决，在一个一主多从的Redis系统
中，可以使用多个哨兵进行监控任务以保证系统足够稳定。此时哨兵不仅会监控master和slave，同时还会互相监
控；这种方式称为哨兵集群，哨兵集群需要解决故障发现、和master决策的协商机制问题。

![哨兵集群架构图](F:\总结\截图\技术篇\Redis\哨兵集群架构图.png)

sentinel节点之间会因为共同监视同一个master从而产生了关联，一个新加入的sentinel节点需要和其他监视相同
master节点的sentinel相互感知，首先：

1. 需要相互感知的sentinel都向他们共同监视的master节点订阅channel:sentinel:hello
2. 新加入的sentinel节点向这个channel发布一条消息，包含自己本身的信息，这样订阅了这个channel的sentinel就可以发现这个新的sentinel
3. 新加入得sentinel和其他sentinel节点建立长连接

![哨兵间相互感知](F:\总结\截图\技术篇\Redis\哨兵间相互感知.png)

##### master 故障发现

`sentinel`节点会定期向master节点发送心跳包来判断存活状态，一旦master节点没有正确响应，`sentinel`会把master设置为“主观不可用状态”，然后它会把“主观不可用”发送给其他所有的`sentinel`节点去确认，当确认的`sentinel`节点数大于>`quorum`时，则会认为master是“客观不可用”，接着就开始进入选举新的master流程；但是这里又会遇到一个问题，就是`sentinel`中，本身是一个集群，如果多个节点同时发现master节点达到客观不可用状态，那谁来决策选择哪个节点作为master呢？这个时候就需要从sentinel集群中选择一个leader来做决策。而这里用到了一致性算法`Raft算法`、它和`Paxos算法`类似，都是`分布式一致性算法`。但是它比`Paxos算法`要更容易理解；`Raft`和`Paxos`算法一样，也是基于投票算法，只要保证过半数节点通过提议即可;

[动画演示地址](http://thesecretlivesofdata.com/raft/)

##### 配置实现

```shell
vim /root/tools/redis-3.2.9/sentinel.conf
```

```shell
sentinel monitor [name] [ip] [port] [quorum]
# 其中name表示要监控的master的名字，这个名字是自己定义。 ip和port表示master的ip和端口号。 最后一个quorum表示最低通过票数，也就是说至少需要几个哨兵节点统一才可以,例如：
sentinel monitor mymaster 127.0.0.1 6379 2
```

启动哨兵

```shell
./bin/redis-sentinel ./sentinel.conf
```

哨兵监控一个系统时，只需要配置监控master即可，哨兵会自动发现所有slave；

这时候，我们把master关闭，等待指定时间后（默认是30秒），会自动进行切换，会输出如下消息：

`+sdown`表示哨兵主观认为master已经停止服务了，`+odown`表示哨兵客观认为master停止服务了。接着哨兵开始进行故障恢复，挑选一个slave升级为master；

`+try-failover`表示哨兵开始进行故障恢复

`+failover-end`表示哨兵完成故障恢复

`+slave`表示列出新的master和slave服务器，我们仍然可以看到已经停掉的master，哨兵并没有清楚已停止的服务的实例，这是因为已经停止的服务器有可能会在某个时间进行恢复，恢复以后会以slave角色加入到整个集群中。

#### 四、Redis-Cluster

即使是使用哨兵，此时的Redis集群的每个数据库依然存有集群中的所有数据，从而导致集群的总数据存储量受限于可用存储内存最小的节点，形成了木桶效应。而因为Redis是基于内存存储的，所以这一个问题在redis中就显得尤为突出了。

在redis3.0之前，我们是通过在客户端去做的分片，通过hash环的方式对key进行分片存储。分片虽然能够解决各个节点的存储压力，但是导致维护成本高、增加、移除节点比较繁琐。因此在redis3.0以后的版本最大的一个好处就是支持集群功能，集群的特点在于拥有和单机实例一样的性能，同时在网络分区以后能够提供一定的可访问性以及对主数据库故障恢复的支持。

哨兵和集群是两个独立的功能，当不需要对数据进行分片使用哨兵就够了，如果要进行水平扩容，集群是一个比较
好的方式。

##### 拓扑结构

一个Redis Cluster由多个Redis节点构成。不同节点组服务的数据没有交集，也就是每个一节点组对应数据
`sharding`的一个分片。节点组内部分为主备两类节点，对应master和slave节点。两者数据准实时一致，通过异步化的主备复制机制来保证。一个节点组有且只有一个master节点，同时可以有0到多个slave节点，在这个节点组中只有master节点对用户提供些服务，读服务可以由master或者slave提供。

![Redis集群拓扑图](F:\总结\截图\技术篇\Redis\Redis集群拓扑图.png)

redis-cluster是基于`gossip`协议实现的无中心化节点的集群，因为去中心化的架构不存在统一的配置中心，各个节点对整个集群状态的认知来自于节点之间的信息交互。在Redis Cluster，这个信息交互是通过Redis Cluster Bus来完成的。

##### Redis 的数据分区

分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集, Redis Cluster采用哈希分区规则,采用虚拟槽分区。

虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。比如Redis Cluster槽的范围是0 ～ 16383。槽是集群内数据管理和迁移的基本单位。采用大范围的槽的主要目的是为了方便数据的拆分和集群的扩展，每个节点负责一定数量的槽。

计算公式：`slot = CRC16(key)%16383`。每一个节点负责维护一部分槽以及槽所映射的键值数据。

##### HashTags

通过分片手段，可以将数据合理的划分到不同的节点上，这本来是一件好事。但是有的时候，我们希望对相关联的业务以原子方式进行操作。举个简单的例子：

我们在单节点上执行MSET , 它是一个原子性的操作，所有给定的key会在同一时间内被设置，不可能出现某些指定的key被更新另一些指定的key没有改变的情况。但是在集群环境下，我们仍然可以执行MSET命令，但它的操作不在是原子操作，会存在某些指定的key被更新，而另外一些指定的key没有改变，原因是多个key可能会被分配到不同的机器上。

所以，这里就会存在一个矛盾点，及要求key尽可能的分散在不同机器，又要求某些相关联的key分配到相同机器。这个也是在面试的时候会容易被问到的内容。怎么解决呢？

分片其实就是一个hash的过程，对key做hash取模然后划分到不同的机器上。所以为了解决这个问题，我们需要考虑如何让相关联的key得到的hash值都相同呢？如果key全部相同是不现实的，所以怎么解决呢？在redis中引入了HashTag的概念，可以使得数据分布算法可以根据key的某一个部分进行计算，然后让相关的key落到同一个数据分片。

举个简单的例子，加入对于用户的信息进行存储， user:user1:id、user:user1:name/ 那么通过hashtag的方式，user:{user1}:id、user:{user1}.name; 表示，当一个key包含 {} 的时候，就不对整个key做hash，而仅对 {} 包括的字符串做hash。

##### 重定向客户端

Redis Cluster并不会代理查询，那么如果客户端访问了一个key并不存在的节点，这个节点是怎么处理的呢？比如我想获取key为msg的值，msg计算出来的槽编号为254，当前节点正好不负责编号为254的槽，那么就会返回客户端下面信息：

```shell
-MOVED 254 127.0.0.1:6381
```

表示客户端想要的254槽由运行在IP为127.0.0.1，端口为6381的Master实例服务。如果根据key计算得出的槽恰好由当前节点负责，则当期节点会立即返回结果。

##### 分片迁移

在一个稳定的Redis cluster下，每一个slot对应的节点是确定的，但是在某些情况下，节点和分片对应的关系会发生变更：

1. 新加入master节点
2. 某个节点宕机

也就是说当动态添加或减少node节点时，需要将16384个槽做个再分配，槽中的键值也要迁移。当然，这一过程，在目前实现中，还处于半自动状态，需要人工介入。

###### 新增一个master节点

参考redis集群安装

###### 删除一个master节点

参考redis集群安装

##### 槽迁移的过程

槽迁移的过程中有一个不稳定状态，这个不稳定状态会有一些规则，这些规则定义客户端的行为，从而使得Redis Cluster不必宕机的情况下可以执行槽的迁移。下面这张图描述了我们迁移编号为1、2、3的槽的过程中，他们在Master A节点和Master B节点中的状态。

![槽迁移过程](F:\总结\截图\技术篇\Redis\槽迁移过程.png)

